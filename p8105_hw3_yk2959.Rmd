---
title: "Homework 3 new"
author: "Kiran Kui"
date: "`r Sys.Date()`"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(readxl)
library(dplyr)
library(rnoaa)
library(hexbin)
library(patchwork)
library(packrat)
library(ggridges)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

# Problem 1

```{r}
#Loading the Instacart data
library(p8105.datasets)
data("instacart")

instacart

```

his dataset contains `r nrow(instacart)` rows and `r ncol(instacart)` columns, with each row resprenting a single product from an instacart order.

Variables include: 

* order id
* product id
* add to cart order
* reordered items
* user id
* evaluation set
* order number
* day of week that order was made
* hour of day that order was made
* days since last order
* product name 
* aisle id
* department id
* aisle 
* department

One of the key variables is the product name purchased at instacart: for instance, "shelled pistachios", "spring water". 

Another key variable is the aisle that the product was purchased: for instance, yoghurt, fresh vegetables, etc. 

In total, there are `r instacart %>% select(product_id) %>% distinct %>% count` products found in `r instacart %>% select(user_id, order_id) %>% distinct %>% count` orders from `r instacart %>% select(user_id) %>% distinct %>% count` distinct users.

```{r}
instacart %>% 
  count(aisle) %>% 
  arrange(desc(n))
```

I created a table summarizing the number of items ordered from aisle. In total, there are 134 aisles. 

```{r}
instacart %>% 
  count(aisle) %>% 
  filter(n > 10000) %>% 
  mutate(aisle = fct_reorder(aisle, n)) %>% 
  ggplot(aes(x = aisle, y = n)) + 
  geom_point() + 
  labs(title = "Number of items ordered in each aisle") +
  theme(axis.text.x = element_text(angle = 60, hjust = 1))

```

I created a plot that shows the number of items ordered in each aisle. Here, aisles are ordered by ascending number of items.

```{r}
instacart %>% 
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>%
  group_by(aisle) %>% 
  count(product_name) %>% 
  mutate(rank = min_rank(desc(n))) %>% 
  filter(rank < 4) %>% 
  arrange(desc(n)) %>%
  knitr::kable()
```

The three most popular items in aisles `baking ingredients`, `dog food care`, and `packaged vegetables fruits`, and includes the number of times each item is ordered.

```{r}
instacart %>%
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>%
  group_by(product_name, order_dow) %>%
  summarize(mean_hour = mean(order_hour_of_day)) %>%
  spread(key = order_dow, value = mean_hour) %>%
  knitr::kable(digits = 2)
```
I created a table showing the mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week.

# Problem 2

I read in, tidied and wrangled the dataset accel_data.csv

```{r}
# Load, tidy and wrangle the data
accel_df <- read_csv("./data/accel_data.csv") %>%
  janitor::clean_names() %>% 
  drop_na(day_id) %>% 
  pivot_longer( 
     cols = activity_1:activity_1440,
     names_to = "activity_minute",
     names_prefix = "activity_",
     values_to = "activity_amount") %>% 
  mutate(wkday_wkend = case_when(
        day == "Saturday" ~ "weekend",
        day == "Sunday" ~ "weekend",
        day == "Monday" ~ "weekday",
        day == "Tuesday" ~ "weekday",
        day == "Wednesday" ~ "weekday",
        day == "Thursday" ~ "weekday",
        day == "Friday" ~ "weekday",
        TRUE ~ ""),
        week = as.integer(week),
        day_id = as.integer(day_id), 
        activity_minute = as.numeric(activity_minute)) %>% 
  mutate(day=fct_relevel(day, "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"))

```

There are `r ncol(accel_df)` rows(observations) and `r nrow(accel_df)` columns variables in this dataset. This dataset describes the activity of a 63-year-old male with a BMI of 25, diagnosed with congestive heart failure at the Advanced Cardiac Care Center of Columbia University Medical Center. 

Each observation(row) aligns with a single activity of this individual. 

There are 6 variables `r colnames(accel_df)`corresponding to week, day ID, day of the week, activity minute, activity amount, and whether the activity was conducted on a weekday or a weekend, respectively.  

```{r}
# New table showing aggregation across minutes
accel_df_2 = accel_df %>% 
group_by(week, day) %>% 
  summarize(total_activity = sum(activity_amount)) %>% 
  pivot_wider(names_from = day,
              values_from = total_activity)
```

I aggregated across minutes to create a total activity variable for each day, and create a table showing these totals called accel_df_2. 

Some trends are apparent. My results show that physical activity was highest on Fridays with and lowest on Saturdays. 

```{r}
#Plot showing the 24-hour activity time courses for each day
ggplot(accel_df, aes(x=activity_minute, y=activity_amount, color=day)) + geom_point() +
  scale_x_continuous(breaks = c(120, 240, 360, 480, 600, 720, 840, 960,1080, 1200, 1320, 1440),
  limits = c(1, 1500)) + 
  labs(title = "Scatterplot showing the 24-hour activity time courses for each day",
    x = "Day",
    y = "Total Activity")

```

I made a single-panel scatterplot that shows the 24-hour activity time courses for each day and use color to indicate day of the week. 

The plot shows on the y-axis, the amount of physical activity, referring to the amount of activity that the individual performed in a specific minute. The x-axis is the activity number, refers to the specific minute that the physical activity was performed. Colors indicate the day of the week.

The scatterplot shows that between 0 to 300 minutes in the day (first 5h of the day between midnight and 5am), there was a low level of activity performed because the individual is likely still sleeping. Then, the level of physical activity increased and is at its peak between 360 minutes and 1320 minutes (between 6am and 10pm). The scatterplot shows that after 1380 minutes (11pm) in the day, the physical activity starts to decline again as the individual winds down for bedtime. 

Furthermore, peak physical activity levels occurs at different times on different days of the week. For instance, the peak physical activity levels on Sunday occurs around 600 minutes to 720 minutes, between 10am and 12pm. On the other hand, peak physical activity levels on Wednesday occurs between 1140 minutes and 1200 minutes, which is around 7pm and 8pm. This indicates that the individual has a different exercise schedule dependent on days of the week. 

# Problem 3

### I have loaded and explored the ny_noaa dataset.  
```{r}
#Loading the dataset and exploring the dataset
library(p8105.datasets)
data("ny_noaa")
```

There are `r ncol(ny_noaa)` rows(observations) and `r nrow(ny_noaa)` columns variables in this dataset. Each row refers to a single daily observation from a weather station in the US.

There are 6 variables `r colnames(ny_noaa)`corresponding to id, date, precipitation (tenths of mm), snow fall (mm), snow depth (mm), maximum and minimum temperature (tenths of degrees C), respectively.

Missing data is a large issue for this dataset. The variables, tmax, tmin, prcp, snow and snwd have large amounts of missing data. 

Missing values is indicated below: 

* The tmax variable is missing `r ny_noaa %>% filter(is.na(tmax)) %>% count` observations. 

* The tmin variable is missing `r ny_noaa %>% filter(is.na(tmin)) %>% count` observations.

* The prcp (precipitation) variable is missing `r ny_noaa %>% filter(is.na(prcp)) %>% count` observations. 

* The snow (snowfall) variable is missing `r ny_noaa %>% filter(is.na(snow)) %>% count` observations. 

* The snwd (snow depth) variable is missing `r ny_noaa %>% filter(is.na(snwd)) %>% count` observations. 


```{r}
# Data cleaning

ny_noaa = ny_noaa %>% 
  janitor::clean_names() %>%
  separate(date, into = c("year", "month", "day"), sep = '-') %>% 
  drop_na(prcp, tmax, tmin, snow, snwd) %>% 
  mutate(tmax = as.numeric(tmax),
         tmin = as.numeric(tmin),
         tmax_c = tmax/10,
         tmin_c = tmin/10,
         prcp_mm = prcp/10,
         month = recode(month, "01" = "January", "02" = "February", "03" = "March", "04" = "April", "05" = "May", "06" = "June", "07" = "July", "08" = "August", "09" = "September", "10" = "October", "11" = "November", "12" = "December")) 
  
```

I have cleaned and tidied my dataset through converting certain variables into standard units. 

Data cleaning: 

* Precipitation (`prcp`) was converted from tenths of mm to mm. 

* Maximum and minimum temperature (`tmax` and `tmin` respectively) were converted from tenths of degrees celsius to degree celsius.

For snowfall, the most commonly observed values is `r names(which.max(table(ny_noaa$snow)))` because most days in the year do not have snow. 

```{r}
#making a plot
avg_max_temp_Jan_July = ny_noaa %>%  
  group_by(id, month, year) %>% 
  filter (month=="January" | month=="July") %>% 
   summarize (average_tmax = mean(tmax_c), na.rm=TRUE) 
  
  
ggplot(avg_max_temp_Jan_July, aes(x=year, y=average_tmax)) +
  geom_point() +
  geom_path() + 
  facet_grid(. ~ month) + 
  labs(title = "Scatterplot showing the average maximum temperature in January and in July in each station across years",
    x = "Year",
    y = "Average maximum temperature") 

# Finding minium maximum average tmax for January 
avg_max_temp_Jan_July %>% 
  filter(month=="January") %>% 
  select(average_tmax, year) %>% 
  arrange(average_tmax)

avg_max_temp_Jan_July %>% 
  filter(month=="July") %>% 
  select(average_tmax, year) %>% 
  arrange(average_tmax)

```

I created a two-panel scatterplot showing the average maximum temperature in January and in July in each station across years. 

Yes, in terms of interpretable structure, comparing the scatterplot for January and July, we can see that the maximum temperatures in January are much lower compared to the maximum temperatures in July.  

* The mean maximum temperatures in January across the years is `r avg_max_temp_Jan_July %>% filter(month == "January") %>% pull(average_tmax) %>% mean()`. 

* The mean maximum temperatures in July across the years is `r avg_max_temp_Jan_July  %>% filter(month == "July") %>% pull(average_tmax) %>% mean()`. This is approximately 27 degree celsius higher than the mean maximum temperature in January. 

* In the scatterplot for January, range of tmax is `r avg_max_temp_Jan_July %>% filter(month == "January") %>% pull(average_tmax) %>% range()`. 

* In the scatterplot for January, range of tmax is `r avg_max_temp_Jan_July %>% filter(month == "July") %>% pull(average_tmax) %>% range()`. 

__Outliers__ 
Yes. There are outliers present. 

In January, there are two outliers of average tmax of -16.6 and -16.1 degree celsius at 1982 and 1996 respectively. These values are lower than the rest of the values. 

In July, there are two outliers of average tmax of 14.0 degree celsius at 1998. This value is lower than the rest of the value. 


```{r}
tmax_tmin = ny_noaa %>% 
  drop_na() %>%
  ggplot(aes(x = tmax_c, y=tmin_c)) + geom_hex() + 
  labs(title = "Hexplot showing depicting maximum temperature versus minimum temperature",
    x = "Maximum temperature in celsius",
    y = "Minimum temperature in celsius") 

snowfall_dist = ny_noaa %>% 
  drop_na() %>%
  filter (snow>0 & snow<100) %>% 
  ggplot(aes(x = snow, y = year)) + geom_density_ridges() + 
  labs(title = "Density ridge line showing the distribution of snowfall values", 
       x="Snowfall (mm)",
       y="year")
                                          
tmax_tmin / snowfall_dist

```

I created a a two-panel plot showing (i) a hexplot depicting tmax vs tmin for the full dataset ; and (ii) a density ridgeline plot showing the distribution of snowfall values greater than 0 and less than 100 separately by year.

